<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Thinker&#39;s</title>
    <link>http://Molldy.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Fri, 13 Apr 2018 08:08:51 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Two-layers Neural Network</title>
      <link>http://Molldy.github.io/2018/04/13/Two-layers%20Neural%20Network/</link>
      <guid>http://Molldy.github.io/2018/04/13/Two-layers%20Neural%20Network/</guid>
      <pubDate>Fri, 13 Apr 2018 08:06:02 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;Two-layers-Neural-Network&quot;&gt;&lt;a href=&quot;#Two-layers-Neural-Network&quot; class=&quot;headerlink&quot; title=&quot;Two-layers Neural Network&quot;&gt;&lt;/a&gt;Two-layers 
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="Two-layers-Neural-Network"><a href="#Two-layers-Neural-Network" class="headerlink" title="Two-layers Neural Network"></a>Two-layers Neural Network</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># data</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:, np.newaxis]  <span class="comment">#-1~1,300个单位</span></span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape)  <span class="comment">#添加噪声，正态分布生成随机数（方差是0.05，格式是x_data.shape）</span></span><br><span class="line">y_data = np.square(x_data) - <span class="number">0.5</span> + noise  <span class="comment">#y=x^2-0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># def Variables &amp; add_layer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function = None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random_normal([in_size, out_size], stddev=<span class="number">0.1</span>))</span><br><span class="line">    biases = tf.Variable(tf.zeros([out_size]) + <span class="number">0.1</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights) + biases</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        output = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = activation_function(Wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># define placeholder</span></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># add layers</span></span><br><span class="line">l1 = add_layer(xs, <span class="number">1</span>, <span class="number">10</span>, activation_function=tf.nn.relu)</span><br><span class="line">prediction = add_layer(l1, <span class="number">10</span>, <span class="number">1</span>, activation_function=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss function</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(prediction - ys), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># session</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.initialize_all_variables())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(sess.run(loss, feed_dict=&#123;xs: x_data, ys: y_data&#125;))</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>http://Molldy.github.io/2018/04/13/Two-layers%20Neural%20Network/#disqus_thread</comments>
    </item>
    
    <item>
      <title>欢迎</title>
      <link>http://Molldy.github.io/2018/04/07/%E6%AC%A2%E8%BF%8E/</link>
      <guid>http://Molldy.github.io/2018/04/07/%E6%AC%A2%E8%BF%8E/</guid>
      <pubDate>Sat, 07 Apr 2018 12:17:03 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;Welcome-to-Hou’s-blog&quot;&gt;&lt;a href=&quot;#Welcome-to-Hou’s-blog&quot; class=&quot;headerlink&quot; title=&quot;Welcome to Hou’s blog&quot;&gt;&lt;/a&gt;Welcome to Hou’s blog&lt;/
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="Welcome-to-Hou’s-blog"><a href="#Welcome-to-Hou’s-blog" class="headerlink" title="Welcome to Hou’s blog"></a>Welcome to Hou’s blog</h2><p>Hello，我是Molldy Hou，欢迎来到我的博客！</p><p>在这里，我会将我所学习到的知识整理下来。欢迎交流。</p>]]></content:encoded>
      
      <comments>http://Molldy.github.io/2018/04/07/%E6%AC%A2%E8%BF%8E/#disqus_thread</comments>
    </item>
    
    <item>
      <title>test</title>
      <link>http://Molldy.github.io/2018/04/07/test/</link>
      <guid>http://Molldy.github.io/2018/04/07/test/</guid>
      <pubDate>Sat, 07 Apr 2018 12:09:44 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;hhhhh&lt;/p&gt;

        
      
      </description>
      
      <content:encoded><![CDATA[<p>hhhhh</p>]]></content:encoded>
      
      <comments>http://Molldy.github.io/2018/04/07/test/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
