<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Thinker&#39;s</title>
    <link>http://Molldy.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Fri, 13 Apr 2018 08:16:45 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>基于MNIST数据集的LeNet-5模型实现</title>
      <link>http://Molldy.github.io/2018/04/13/%E5%9F%BA%E4%BA%8EMNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84LeNet-5%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/</link>
      <guid>http://Molldy.github.io/2018/04/13/%E5%9F%BA%E4%BA%8EMNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84LeNet-5%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/</guid>
      <pubDate>Fri, 13 Apr 2018 08:11:56 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;基于MNIST数据集的LeNet-5模型实现&quot;&gt;&lt;a href=&quot;#基于MNIST数据集的LeNet-5模型实现&quot; class=&quot;headerlink&quot; title=&quot;基于MNIST数据集的LeNet-5模型实现&quot;&gt;&lt;/a&gt;基于MNIST数据集的LeNet-5模型
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="基于MNIST数据集的LeNet-5模型实现"><a href="#基于MNIST数据集的LeNet-5模型实现" class="headerlink" title="基于MNIST数据集的LeNet-5模型实现"></a>基于MNIST数据集的LeNet-5模型实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># data</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data/'</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># def Variables&amp;add_layer</span></span><br><span class="line"><span class="comment">#   定义准确率输出函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_accuracy</span><span class="params">(v_xs, v_ys)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> prediction</span><br><span class="line">    y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs, keep_prob: <span class="number">1</span>&#125;)</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y_pre, <span class="number">1</span>), tf.argmax(v_ys, <span class="number">1</span>)) <span class="comment"># 找出预测正确的标签</span></span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) <span class="comment"># 得出通过正确个数除以总数得出准确率</span></span><br><span class="line">    result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys, keep_prob: <span class="number">1</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Weights_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(tf.truncated_normal(shape, stddev=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biases_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(tf.zeros(shape) + <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># placeholder</span></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line">xs_image = tf.reshape(xs, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]) <span class="comment"># [batch, in_size, out_size, in_channels]</span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)  <span class="comment"># dropout层参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># add layers</span></span><br><span class="line"><span class="comment"># conv1 layer</span></span><br><span class="line">W_conv1 = Weights_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>]) <span class="comment"># [filter_height, filter_width, in_channels, out_channels]</span></span><br><span class="line">b_conv1 = biases_variable([<span class="number">32</span>])</span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(xs_image, W_conv1) + b_conv1)</span><br><span class="line">h_pool1 = max_pool(h_conv1) <span class="comment"># pooling layer, out_size=14x14x32</span></span><br><span class="line"><span class="comment"># conv2 layer</span></span><br><span class="line">W_conv2 = Weights_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>]) <span class="comment"># [filter_height, filter_width, in_channels, out_channels]</span></span><br><span class="line">b_conv2 = biases_variable([<span class="number">64</span>])</span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">h_pool2 = max_pool(h_conv2) <span class="comment"># pooling layer, out_size=7x7x64</span></span><br><span class="line"><span class="comment"># func1 layer</span></span><br><span class="line">W_func1 = Weights_variable([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>, <span class="number">1024</span>])</span><br><span class="line">b_func1 = biases_variable([<span class="number">1024</span>])</span><br><span class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>]) <span class="comment"># 将h_pool2变成1维的数据</span></span><br><span class="line">h_func1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_func1) + b_func1)</span><br><span class="line">h_func1_drop = tf.nn.dropout(h_func1, keep_prob) <span class="comment"># dropout layer</span></span><br><span class="line"><span class="comment"># func2 layer</span></span><br><span class="line">W_func2 = Weights_variable([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">b_func2 = biases_variable([<span class="number">10</span>])</span><br><span class="line">prediction = tf.nn.softmax(tf.matmul(h_func1_drop, W_func2) + b_func2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss function</span></span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),</span><br><span class="line">                                              reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># train_step</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Session</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.initialize_all_variables())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs: batch_xs, ys: batch_ys, keep_prob: <span class="number">0.5</span>&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        print(compute_accuracy(</span><br><span class="line">            mnist.test.images, mnist.test.labels))</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>http://Molldy.github.io/2018/04/13/%E5%9F%BA%E4%BA%8EMNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84LeNet-5%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Two-layers Neural Network</title>
      <link>http://Molldy.github.io/2018/04/13/Two-layers%20Neural%20Network/</link>
      <guid>http://Molldy.github.io/2018/04/13/Two-layers%20Neural%20Network/</guid>
      <pubDate>Fri, 13 Apr 2018 08:06:02 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;简单2层神经网络模型实现&quot;&gt;&lt;a href=&quot;#简单2层神经网络模型实现&quot; class=&quot;headerlink&quot; title=&quot;简单2层神经网络模型实现&quot;&gt;&lt;/a&gt;简单2层神经网络模型实现&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="简单2层神经网络模型实现"><a href="#简单2层神经网络模型实现" class="headerlink" title="简单2层神经网络模型实现"></a>简单2层神经网络模型实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># data</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">300</span>)[:, np.newaxis]  <span class="comment">#-1~1,300个单位</span></span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape)  <span class="comment">#添加噪声，正态分布生成随机数（方差是0.05，格式是x_data.shape）</span></span><br><span class="line">y_data = np.square(x_data) - <span class="number">0.5</span> + noise  <span class="comment">#y=x^2-0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># def Variables &amp; add_layer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function = None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random_normal([in_size, out_size], stddev=<span class="number">0.1</span>))</span><br><span class="line">    biases = tf.Variable(tf.zeros([out_size]) + <span class="number">0.1</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights) + biases</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        output = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = activation_function(Wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># define placeholder</span></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># add layers</span></span><br><span class="line">l1 = add_layer(xs, <span class="number">1</span>, <span class="number">10</span>, activation_function=tf.nn.relu)</span><br><span class="line">prediction = add_layer(l1, <span class="number">10</span>, <span class="number">1</span>, activation_function=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss function</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(prediction - ys), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># session</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.initialize_all_variables())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(sess.run(loss, feed_dict=&#123;xs: x_data, ys: y_data&#125;))</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      <comments>http://Molldy.github.io/2018/04/13/Two-layers%20Neural%20Network/#disqus_thread</comments>
    </item>
    
    <item>
      <title>欢迎</title>
      <link>http://Molldy.github.io/2018/04/07/%E6%AC%A2%E8%BF%8E/</link>
      <guid>http://Molldy.github.io/2018/04/07/%E6%AC%A2%E8%BF%8E/</guid>
      <pubDate>Sat, 07 Apr 2018 12:17:03 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;Welcome-to-Hou’s-blog&quot;&gt;&lt;a href=&quot;#Welcome-to-Hou’s-blog&quot; class=&quot;headerlink&quot; title=&quot;Welcome to Hou’s blog&quot;&gt;&lt;/a&gt;Welcome to Hou’s blog&lt;/
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="Welcome-to-Hou’s-blog"><a href="#Welcome-to-Hou’s-blog" class="headerlink" title="Welcome to Hou’s blog"></a>Welcome to Hou’s blog</h2><p>Hello，我是Molldy Hou，欢迎来到我的博客！</p><p>在这里，我会将我所学习到的知识整理下来。欢迎交流。</p>]]></content:encoded>
      
      <comments>http://Molldy.github.io/2018/04/07/%E6%AC%A2%E8%BF%8E/#disqus_thread</comments>
    </item>
    
    <item>
      <title>test</title>
      <link>http://Molldy.github.io/2018/04/07/test/</link>
      <guid>http://Molldy.github.io/2018/04/07/test/</guid>
      <pubDate>Sat, 07 Apr 2018 12:09:44 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;hhhhh&lt;/p&gt;

        
      
      </description>
      
      <content:encoded><![CDATA[<p>hhhhh</p>]]></content:encoded>
      
      <comments>http://Molldy.github.io/2018/04/07/test/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
